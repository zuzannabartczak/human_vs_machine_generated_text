{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split, learning_curve, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation and preprocessing\n",
    "\n",
    "# Load the dataset\n",
    "with open('data_json/SubtaskB/subtaskB_train.jsonl', 'r') as f:\n",
    "    df = pd.read_json(f, lines=True, orient='records')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['model'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open('data_json/SubtaskB/subtaskB_dev.jsonl', 'r') as f:\n",
    "    dev_df = pd.read_json(f, lines=True, orient='records')\n",
    "\n",
    "dev_df = dev_df.sample(frac=1, random_state=42)\n",
    "dev_df['text'], dev_df['model'] = X_dev, y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder on the string labels\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "# Transform the string labels to integer values\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_dev = label_encoder.transform(y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize training and testing sets\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(sequences_train, maxlen=100, truncating='post')\n",
    "\n",
    "tokenizer.fit_on_texts(X_test)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(sequences_test, maxlen=100, truncating='post')\n",
    "\n",
    "tokenizer.fit_on_texts(X_dev)\n",
    "sequences_dev = tokenizer.texts_to_sequences(X_dev)\n",
    "X_dev = pad_sequences(sequences_dev, maxlen=100, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1776/1776 [==============================] - 53s 29ms/step - loss: 1.4663 - accuracy: 0.3515\n",
      "Epoch 2/7\n",
      "1776/1776 [==============================] - 51s 29ms/step - loss: 1.2540 - accuracy: 0.4745\n",
      "Epoch 3/7\n",
      "1776/1776 [==============================] - 53s 30ms/step - loss: 1.1688 - accuracy: 0.5274\n",
      "Epoch 4/7\n",
      "1776/1776 [==============================] - 54s 31ms/step - loss: 0.9780 - accuracy: 0.6237\n",
      "Epoch 5/7\n",
      "1776/1776 [==============================] - 57s 32ms/step - loss: 0.8510 - accuracy: 0.6841\n",
      "Epoch 6/7\n",
      "1776/1776 [==============================] - 57s 32ms/step - loss: 0.7070 - accuracy: 0.7457\n",
      "Epoch 7/7\n",
      "1776/1776 [==============================] - 53s 30ms/step - loss: 0.5527 - accuracy: 0.8088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cf8cfc460>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Convert the target labels to one-hot encoded format\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_one_hot, epochs=7, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 4s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Predict the probabilities for the test set\n",
    "probabilities = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted probabilities to a DataFrame\n",
    "probabilities_df = pd.DataFrame(probabilities, columns=['0', '1', '2', '3', '4', '5'])\n",
    "\n",
    "probabilities = list(zip(y_test_one_hot, probabilities.flatten()))\n",
    "probabilities_df['actual'] = label_encoder.inverse_transform(y_test)\n",
    "probabilities_df.to_csv('statistics/RNN_B_outputs/ROC.csv', index=False)\n",
    "\n",
    "probabilities_df['predicted'] = probabilities_df[['0', '1', '2', '3', '4', '5']].idxmax(axis=1)\n",
    "\n",
    "y_pred = probabilities_df['predicted'].astype(int)\n",
    "y_pred = y_pred.to_numpy()\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "probabilities_df.to_csv('statistics/RNN_B_outputs/probabilities.csv', index=False)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70      2404\n",
      "           1       0.25      0.22      0.23      2441\n",
      "           2       0.30      0.35      0.32      2204\n",
      "           3       0.21      0.23      0.22      2407\n",
      "           4       0.20      0.21      0.20      2360\n",
      "           5       0.23      0.24      0.24      2390\n",
      "\n",
      "    accuracy                           0.31     14206\n",
      "   macro avg       0.33      0.31      0.32     14206\n",
      "weighted avg       0.33      0.31      0.32     14206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "classification_report_df.to_csv('statistics/RNN_B_outputs/classification_report.csv', index=False)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "confusion_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "confusion_df.to_csv('statistics/RNN_B_outputs/confusion_matrix.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights of the embedding layer\n",
    "embedding_weights = model.get_weights()[0]\n",
    "\n",
    "# Get the word index from the tokenizer\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Create a list of (word, weight) pairs\n",
    "word_weights = []\n",
    "for word, index in word_index.items():\n",
    "    if index < embedding_weights.shape[0]:\n",
    "        weight = np.linalg.norm(embedding_weights[index])\n",
    "        word_weights.append((word, weight))\n",
    "\n",
    "# Store the weights in a csv file\n",
    "sorted_features = sorted(word_weights, key=lambda x: x[1])\n",
    "\n",
    "# Print the weights of the top 30 words to a file\n",
    "with open(\"statistics/RNN_B_outputs/top_bottom_words.csv\", \"w\") as f:\n",
    "    f.write(f\"word,weight\\n\")\n",
    "    for word, weight in sorted_features[-30:]:\n",
    "        f.write(f\"{word},{weight}\\n\")\n",
    "\n",
    "    # Print the weights of the bottom 30 words to the same file\n",
    "    for word, weight in sorted_features[:30]:\n",
    "        f.write(f\"{word},{weight}\\n\")\n",
    "\n",
    "# Store all of the weights in a separate csv file\n",
    "weights_df = pd.DataFrame(sorted_features, columns=['word', 'weight'])\n",
    "weights_df.to_csv('statistics/RNN_B_outputs/weights.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 8ms/step\n",
      "Accuracy: 0.2723333333333333\n"
     ]
    }
   ],
   "source": [
    "y_dev_one_hot = tf.keras.utils.to_categorical(y_dev, num_classes)\n",
    "\n",
    "# Predict the labels for the dev set\n",
    "predictions = model.predict(X_dev)\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions, columns=['0', '1', '2', '3', '4', '5'])\n",
    "\n",
    "predictions = list(zip(y_dev_one_hot, predictions.flatten()))\n",
    "predictions_df['actual'] = label_encoder.inverse_transform(y_dev)\n",
    "predictions_df['predicted'] = predictions_df[['0', '1', '2', '3', '4', '5']].idxmax(axis=1).astype(int)\n",
    "\n",
    "predictions_df['id'] = dev_df['id']\n",
    "predictions_df['predicted'] = predictions_df['predicted'].astype(int)\n",
    "predictions_df['model'] = label_encoder.inverse_transform(predictions_df['predicted'])\n",
    "\n",
    "# Save the predictions along with 'id' to a JSONL file\n",
    "predictions_df[['id', 'model']].to_json('statistics/RNN_B_outputs/dev_predictions.jsonl', lines=True, orient='records')\n",
    "\n",
    "predicted_labels = predictions_df['predicted'].values\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = sum(y_dev == predicted_labels) / len(y_dev)\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67       403\n",
      "           1       0.14      0.20      0.16       340\n",
      "           2       0.26      0.24      0.25       555\n",
      "           3       0.21      0.21      0.21       505\n",
      "           4       0.20      0.17      0.19       582\n",
      "           5       0.22      0.18      0.20       615\n",
      "\n",
      "    accuracy                           0.27      3000\n",
      "   macro avg       0.27      0.29      0.28      3000\n",
      "weighted avg       0.26      0.27      0.27      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_model = probabilities_df['predicted'].astype(int)\n",
    "pred_model = pred_model.to_numpy()\n",
    "\n",
    "classification_report2_df = pd.DataFrame(\n",
    "    classification_report(predicted_labels, y_dev, output_dict=True)).transpose()\n",
    "classification_report2_df.to_csv(\n",
    "    'statistics/RNN_B_outputs/classification_report2.csv', index=False)\n",
    "\n",
    "print(classification_report(predicted_labels, y_dev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Evaluate the model\n",
    "# model.evaluate(X_test, y_test_one_hot)\n",
    "\n",
    "# # Save the model\n",
    "# model.save('models/RNNmodelB.h5')\n",
    "\n",
    "# # Load the model\n",
    "# model = tf.keras.models.load_model('models/RNNmodelB.h5')\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Convert the predictions to integer format\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# # Convert the integer predictions to string labels\n",
    "# y_pred = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# # Convert the test set labels to string format\n",
    "# y_test = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Print the confusion matrix\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# # Save the label encoder\n",
    "# with open('models/label_encoderB.json', 'w') as f:\n",
    "#     json.dump(label_encoder.classes_.tolist(), f)\n",
    "\n",
    "# # Plot the learning curve\n",
    "# train_sizes, train_scores, test_scores = learning_curve(model, X_train, y_train, cv=5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.style.use('seaborn')\n",
    "# plt.plot(train_sizes, train_scores_mean, label='Training accuracy')\n",
    "# plt.plot(train_sizes, test_scores_mean, label='Validation accuracy')\n",
    "# plt.ylabel('Accuracy', fontsize=14)\n",
    "# plt.xlabel('Training set size', fontsize=14)\n",
    "# plt.title('Learning curves for RNN model', fontsize=18, y=1.03)\n",
    "# plt.legend()\n",
    "# plt.ylim(0.5, 1)\n",
    "# plt.show()\n",
    "\n",
    "# # Hyperparameter tuning\n",
    "\n",
    "# # Define the hyperparameter grid\n",
    "# param_grid = {'batch_size': [32, 64, 128],\n",
    "#               'epochs': [5, 10, 15]}\n",
    "\n",
    "# # Define the random search\n",
    "# random_search = RandomizedSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# # Train the random search\n",
    "# random_search.fit(X_train, y_train_one_hot)\n",
    "\n",
    "# # Print the best set of parameters\n",
    "# print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# # Print the best score\n",
    "# print(\"Best score found: \", random_search.best_score_)\n",
    "\n",
    "# # Save the best model\n",
    "# random_search.best_estimator_.model.save('models/RNNmodelB_best.h5')\n",
    "\n",
    "# # Load the best model\n",
    "# model = tf.keras.models.load_model('models/RNNmodelB_best.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning / grid search\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import SimpleRNN, Dense\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Function to create model, required for KerasClassifier\n",
    "# def create_model(units=50, optimizer='adam'):\n",
    "#     model = Sequential()\n",
    "#     model.add(SimpleRNN(units, input_shape=(100, 1)))  # Assume input sequences of length 100\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Create the KerasClassifier wrapper\n",
    "# model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# # Define the grid search parameters\n",
    "# param_grid = {\n",
    "#     'units': [50, 100, 150],\n",
    "#     'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'],\n",
    "#     'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "#     'epochs': [10, 50, 100]\n",
    "# }\n",
    "\n",
    "# # Create Grid Search\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# # Report Results\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
